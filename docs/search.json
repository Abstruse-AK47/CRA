[
  {
    "objectID": "main.html",
    "href": "main.html",
    "title": "Credit Risk Assesment using bayesian Decision Thoery with noisy Financial Data",
    "section": "",
    "text": "Code\nimport pandas as pd\nimport numpy as np"
  },
  {
    "objectID": "main.html#load-uci-credit-approval-dataset",
    "href": "main.html#load-uci-credit-approval-dataset",
    "title": "Credit Risk Assesment using bayesian Decision Thoery with noisy Financial Data",
    "section": "Load UCI Credit Approval dataset",
    "text": "Load UCI Credit Approval dataset\n\n\nCode\nurl = \"https://archive.ics.uci.edu/ml/machine-learning-databases/credit-screening/crx.data\"\ncolumns = [\"Gender\", \"Age\", \"Debt\", \"Married\", \"BankCustomer\", \n           \"EducationLevel\", \"Ethnicity\", \"YearsEmployed\", \n           \"PriorDefault\", \"Employed\", \"CreditScore\", \n           \"DriversLicense\", \"Citizen\", \"ZipCode\", \"Income\", \"Approved\"]\n\n# Replace '?' with NaN\ndata = pd.read_csv(url, names=columns, na_values=\"?\")\n\ndata.head()\n\n\n\n\n\n\n\n\n\nGender\nAge\nDebt\nMarried\nBankCustomer\nEducationLevel\nEthnicity\nYearsEmployed\nPriorDefault\nEmployed\nCreditScore\nDriversLicense\nCitizen\nZipCode\nIncome\nApproved\n\n\n\n\n0\nb\n30.83\n0.000\nu\ng\nw\nv\n1.25\nt\nt\n1\nf\ng\n202.0\n0\n+\n\n\n1\na\n58.67\n4.460\nu\ng\nq\nh\n3.04\nt\nt\n6\nf\ng\n43.0\n560\n+\n\n\n2\na\n24.50\n0.500\nu\ng\nq\nh\n1.50\nt\nf\n0\nf\ng\n280.0\n824\n+\n\n\n3\nb\n27.83\n1.540\nu\ng\nw\nv\n3.75\nt\nt\n5\nt\ng\n100.0\n3\n+\n\n\n4\nb\n20.17\n5.625\nu\ng\nw\nv\n1.71\nt\nf\n0\nf\ns\n120.0\n0\n+"
  },
  {
    "objectID": "main.html#add-noise-to-income-column",
    "href": "main.html#add-noise-to-income-column",
    "title": "Credit Risk Assesment using bayesian Decision Thoery with noisy Financial Data",
    "section": "Add noise to ‘Income’ column",
    "text": "Add noise to ‘Income’ column\n\nSimulating Noisy Features:\n→ Added Gaussian noise to numeric columns(eg.,income):\n\n\n\nCode\nnoise_level = 0.1  # 10% noise\ndata[\"Income_noisy\"] = data[\"Income\"] + np.random.normal(0, noise_level * data[\"Income\"].std(), len(data))\n\n# Replace 'Income' with noisy version for simulation\ndata[\"Income\"] = data[\"Income_noisy\"]\ndata.drop(columns=[\"Income_noisy\"], inplace=True)"
  },
  {
    "objectID": "main.html#handling-missing-data",
    "href": "main.html#handling-missing-data",
    "title": "Credit Risk Assesment using bayesian Decision Thoery with noisy Financial Data",
    "section": "Handling Missing Data",
    "text": "Handling Missing Data\n\nIdentify non-numeric columns\n\n\n\nCode\nnon_numeric_columns = data.select_dtypes(include=[\"object\"]).columns\nnon_numeric_columns\n\n\nIndex(['Gender', 'Married', 'BankCustomer', 'EducationLevel', 'Ethnicity',\n       'PriorDefault', 'Employed', 'DriversLicense', 'Citizen', 'Approved'],\n      dtype='object')\n\n\n\nSeparate numeric and non-numeric columns and calculate missing data\n\n\n\nCode\nfrom sklearn.impute import SimpleImputer\n\nnumeric_data = data.select_dtypes(include=[\"number\"])\ncategorical_data = data.select_dtypes(exclude=[\"number\"])\n\n# Impute numeric columns\nimputer_numeric = SimpleImputer(strategy=\"mean\")\nnumeric_data_imputed = pd.DataFrame(imputer_numeric.fit_transform(numeric_data), columns=numeric_data.columns)\n\n# Impute categorical columns (e.g., with the most frequent value)\nimputer_categorical = SimpleImputer(strategy=\"most_frequent\")\ncategorical_data_imputed = pd.DataFrame(imputer_categorical.fit_transform(categorical_data), columns=categorical_data.columns)\n\n# Combine numeric and categorical data\ndata_imputed = pd.concat([numeric_data_imputed, categorical_data_imputed], axis=1)\n\n# Check the final imputed dataset\ndata_imputed.head()\n\n\n\n\n\n\n\n\n\nAge\nDebt\nYearsEmployed\nCreditScore\nZipCode\nIncome\nGender\nMarried\nBankCustomer\nEducationLevel\nEthnicity\nPriorDefault\nEmployed\nDriversLicense\nCitizen\nApproved\n\n\n\n\n0\n30.83\n0.000\n1.25\n1.0\n202.0\n-1317.942659\nb\nu\ng\nw\nv\nt\nt\nf\ng\n+\n\n\n1\n58.67\n4.460\n3.04\n6.0\n43.0\n187.302150\na\nu\ng\nq\nh\nt\nt\nf\ng\n+\n\n\n2\n24.50\n0.500\n1.50\n0.0\n280.0\n1473.530678\na\nu\ng\nq\nh\nt\nf\nf\ng\n+\n\n\n3\n27.83\n1.540\n3.75\n5.0\n100.0\n-54.282047\nb\nu\ng\nw\nv\nt\nt\nt\ng\n+\n\n\n4\n20.17\n5.625\n1.71\n0.0\n120.0\n-363.372516\nb\nu\ng\nw\nv\nt\nf\nf\ns\n+"
  },
  {
    "objectID": "main.html#dataset-visualization",
    "href": "main.html#dataset-visualization",
    "title": "Credit Risk Assesment using bayesian Decision Thoery with noisy Financial Data",
    "section": "Dataset Visualization",
    "text": "Dataset Visualization\n\nDistribution of target variable\n\n\n\nCode\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Plot the distribution of the target variable\nsns.countplot(data=data_imputed, x=\"Approved\",hue = \"Approved\", palette=\"viridis\")\nplt.xlabel(\"Approval Status\")\nplt.ylabel(\"Count\")\nplt.show()\n\n\n\n\n\n\n\n\nFigure 1: Distribution of Target Variable (Approved)\n\n\n\n\n\n\nPairplot of Feature Relationships\n\n\n\nCode\ndata_without_zip = data_imputed.drop(columns=[\"ZipCode\"])\n\n# pairplot without the 'ZipCode' feature\nsns.pairplot(data_without_zip, hue=\"Approved\", diag_kind=\"kde\", palette=\"coolwarm\",height=1 ,aspect=1)\nplt.show()\n\n\n\n\n\n\n\n\nFigure 2: Pairplot of Features by Approval Status"
  },
  {
    "objectID": "main.html#visualizing-missing-data",
    "href": "main.html#visualizing-missing-data",
    "title": "Credit Risk Assesment using bayesian Decision Thoery with noisy Financial Data",
    "section": "Visualizing Missing Data",
    "text": "Visualizing Missing Data\n\n\nCode\nimport missingno as msno\n\n# Visualize missing data\nmsno.matrix(data)\nplt.show()\n\n\n\n\n\n\n\n\nFigure 3: Missing Values Matrix"
  },
  {
    "objectID": "main.html#bayesian-classifier-implementation",
    "href": "main.html#bayesian-classifier-implementation",
    "title": "Credit Risk Assesment using bayesian Decision Thoery with noisy Financial Data",
    "section": "Bayesian Classifier Implementation",
    "text": "Bayesian Classifier Implementation\n\nDefine Priors:\n→ Calculate prior probabilities\n\n\n\nCode\nprior_approved = data[\"Approved\"].value_counts(normalize=True)[\"+\"]\nprior_denied = data[\"Approved\"].value_counts(normalize=True)[\"-\"]\n\nprint(f\"Prior P(Approved): {prior_approved}, P(Denied): {prior_denied}\")\n\n\nPrior P(Approved): 0.4449275362318841, P(Denied): 0.5550724637681159\n\n\n\nLikelihood Estimation:\n→ Fit a Gaussian for ‘Income’ by class\n\n\n\nCode\nfrom scipy.stats import norm\n\napproved_income = data[data[\"Approved\"] == \"+\"][\"Income\"]\ndenied_income = data[data[\"Approved\"] == \"-\"][\"Income\"]\n\nlikelihood_approved = norm(approved_income.mean(), approved_income.std())\nlikelihood_denied = norm(denied_income.mean(), denied_income.std())\n\n\n\nPosterior Calculation:\n→ Using Bayes’ theorum to compute posterior porbabilities:\n\\[P(\\text{Approved}|\\text{Income})=\\frac{P(\\text{Income}|\\text{Approved})\\cdot P(\\text{Approved})}{P(\\text{Income})}\\]\n\n\n\nCode\ndef posterior(income, prior, likelihood):\n    return prior * likelihood.pdf(income)\n\n# New applicant with income=5000\nnew_income = 5000\np_approved = posterior(new_income, prior_approved, likelihood_approved)\np_denied = posterior(new_income, prior_denied, likelihood_denied)\n\n# Normalize posteriors\ntotal_prob = p_approved + p_denied\np_approved /= total_prob\np_denied /= total_prob\n\nprint(f\"P(Approved|Income): {p_approved}, P(Denied|Income): {p_denied}\")\n\n\nP(Approved|Income): 0.9999987556897033, P(Denied|Income): 1.2443102967852707e-06"
  },
  {
    "objectID": "main.html#decision-rule",
    "href": "main.html#decision-rule",
    "title": "Credit Risk Assesment using bayesian Decision Thoery with noisy Financial Data",
    "section": "Decision Rule",
    "text": "Decision Rule\n\nMap Decision:\n→ The class with highest posterior probability:\n\n\n\nCode\ndecision = \"Approved\" if p_approved &gt; p_denied else \"Denied\"\nprint(f\"Decision: {decision}\")\n\n\nDecision: Approved\n\n\n\nCost-Sensitive Decision:\n→ Incoporated a cost matrix(eg - false negatives are more costly):\n\n\n\nCode\n# Cost matrix: [ [TN, FP], [FN, TP] ]\ncost_matrix = [[0, 1], [5, 0]]  # High cost for FN\n\n# expected cost\nexpected_cost_approved = cost_matrix[1][0] * p_denied  # FN cost\nexpected_cost_denied = cost_matrix[0][1] * p_approved  # FP cost\n\nfinal_decision = \"Approved\" if expected_cost_approved &lt; expected_cost_denied else \"Denied\"\nprint(f\"Cost-sensitive Decision: {final_decision}\")\n\n\nCost-sensitive Decision: Approved\n\n\n\n\nCode\nimport math\n\n# List of columns to plot\ncolumns_to_plot = [\"CreditScore\", \"Age\", \"Debt\", \"Income\"]\n\n# Calculate rows and columns for a grid\nn_features = len(columns_to_plot)\nn_cols = 2  # Number of columns in the grid\nn_rows = math.ceil(n_features / n_cols)  # Calculate required rows (3 in this case)\n\n# Create subplots\nfig, axes = plt.subplots(n_rows, n_cols, figsize=(6, 5))  # Adjust size as needed\naxes = axes.flatten()  # Flatten to easily index subplots\n\n# Plot each feature\nfor i, col in enumerate(columns_to_plot):\n    sns.histplot(data_imputed[col], kde=True, bins=30, color=\"blue\", ax=axes[i])\n    axes[i].set_xlabel(col, fontsize=8)\n    axes[i].set_ylabel(\"Frequency\", fontsize=8)\n    axes[i].tick_params(axis=\"both\", labelsize=7)\n\n# Remove any unused axes\nfor j in range(i + 1, len(axes)):\n    fig.delaxes(axes[j])\n\n# Adjust layout\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nFigure 4: Distribution of Features\n\n\n\n\n\n\n\nCode\n# Correlation heatmap\nnumeric_data_usefull = numeric_data.drop(columns= [\"ZipCode\",\"YearsEmployed\"])\nplt.figure(figsize=(10, 8))\nsns.heatmap(numeric_data_usefull.corr(), annot=True, cmap=\"coolwarm\", fmt=\".2f\")\nplt.show()\n\n\n\n\n\n\n\n\nFigure 5: Correlation Heatmap"
  },
  {
    "objectID": "main.html#model-evaulation",
    "href": "main.html#model-evaulation",
    "title": "Credit Risk Assesment using bayesian Decision Thoery with noisy Financial Data",
    "section": "Model Evaulation",
    "text": "Model Evaulation\n\nEvaulated the models performance with metrics like accuracy, precision, and recall.\n\n\n\nCode\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n\n# Split the data into features and target\nX = data_imputed.drop(columns=[\"Approved\"])\ny = data_imputed[\"Approved\"]\n\n# Identify categorical columns\ncategorical_columns = X.select_dtypes(include=[\"object\"]).columns\n\n# Apply one-hot encoding to categorical columns\nX_encoded = pd.get_dummies(X, columns=categorical_columns, drop_first=True)\n\n\n\n# Split the dataset into training and test sets (70% train, 30% test)\nX_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.3, random_state=42)\n\n# Initialize the Naive Bayes classifier\nmodel = GaussianNB()\n\n# Train the model\nmodel.fit(X_train, y_train)\n\n# Make predictions on the test set\ny_pred = model.predict(X_test)\n\n# Evaluate the model\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred, pos_label='+')\nrecall = recall_score(y_test, y_pred, pos_label='+')\n\n# Confusion Matrix\ncm = confusion_matrix(y_test, y_pred, labels=model.classes_)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\ndisp.plot(cmap=\"Blues\")\nplt.show()\n\n\n\n\n\n\n\n\nFigure 6: Confusion Matrix"
  },
  {
    "objectID": "main.html#results",
    "href": "main.html#results",
    "title": "Credit Risk Assesment using bayesian Decision Thoery with noisy Financial Data",
    "section": "Results",
    "text": "Results\n\n\nCode\nfrom sklearn.metrics import f1_score\n\nf1 = f1_score(y_test, y_pred, pos_label='+')\nprint(f\"F1 Score: {f1:.4f}\")\nprint(f\"Accuracy: {accuracy:.4f}\")\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Recall: {recall:.4f}\")\n\n\nF1 Score: 0.7978\nAccuracy: 0.8213\nPrecision: 0.8488\nRecall: 0.7526\n\n\n\n\nCode\n# Bapr Plot of Model Metrics\nmetrics = [\"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"]\nscores = [accuracy, precision, recall,f1]\n\nplt.figure(figsize=(8, 5))\nsns.barplot(x=metrics, y=scores, hue = metrics, palette=\"viridis\")\nplt.ylim(0, 1)\nplt.ylabel(\"Score\")\nplt.savefig('output.jpg')\nplt.show()\n\n\n\n\n\n\n\n\nFigure 7: Model Performance Metrics\n\n\n\n\n\n\n\nCode\n# Precision-Recall Curve\nfrom sklearn.metrics import precision_recall_curve\nprecision, recall, thresholds = precision_recall_curve(y_test, model.predict_proba(X_test)[:, 1], pos_label='+')\nplt.figure(figsize=(8, 6))\nplt.plot(recall, precision, marker=\".\", label=\"Naive Bayes\")\nplt.xlabel(\"Recall\")\nplt.ylabel(\"Precision\")\nplt.grid()\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nFigure 8: Precision-Recall Curve"
  }
]