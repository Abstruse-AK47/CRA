---
title: Credit Risk Assesment using bayesian Decision Thoery with noisy Financial Data 
format:
 html:
     code-fold: true
jupyter: python3
---

```{python}
#DataFrame Libraries
import pandas as pd
import numpy as np

#Plot Libraries
import matplotlib.pyplot as plt
import seaborn as sns
import missingno as msno

```

## Load UCI Credit Approval dataset

```{python}

url = "https://archive.ics.uci.edu/ml/machine-learning-databases/credit-screening/crx.data"
columns = ["Gender", "Age", "Debt", "Married", "BankCustomer", 
           "EducationLevel", "Ethnicity", "YearsEmployed", 
           "PriorDefault", "Employed", "CreditScore", 
           "DriversLicense", "Citizen", "ZipCode", "Income", "Approved"]

# Replace '?' with NaN
data = pd.read_csv(url, names=columns, na_values="?")

data.head()
```

## Add noise to 'Income' column

- Simulating Noisy Features:

  → Added Gaussian noise to numeric columns(eg.,income):

```{python}

noise_level = 0.1  # 10% noise
data["Income_noisy"] = data["Income"] + np.random.normal(0, noise_level * data["Income"].std(), len(data))

# Replace 'Income' with noisy version for simulation
data["Income"] = data["Income_noisy"]
data.drop(columns=["Income_noisy"], inplace=True)
```

## Finding Relevant and Handling Missing Data 

- Visualize Missing Values

```{python}
#| label: fig-polar
#| fig-cap: Missing Values Matrix


# Visualize missing data
msno.matrix(data)
plt.gcf().set_size_inches(7, 5)
plt.show()
```

- Separate numeric and non-numeric columns and calculate missing data

```{python}
from sklearn.impute import SimpleImputer

numeric_data = data.select_dtypes(include=["number"])
categorical_data = data.select_dtypes(exclude=["number"])

# Impute numeric columns
imputer_numeric = SimpleImputer(strategy="mean")
numeric_data_imputed = pd.DataFrame(imputer_numeric.fit_transform(numeric_data), columns=numeric_data.columns)

# Impute categorical columns (e.g., with the most frequent value)
imputer_categorical = SimpleImputer(strategy="most_frequent")
categorical_data_imputed = pd.DataFrame(imputer_categorical.fit_transform(categorical_data), columns=categorical_data.columns)

# Combine numeric and categorical data
data_imputed = pd.concat([numeric_data_imputed, categorical_data_imputed], axis=1)

# Check the final imputed dataset
data_imputed.head()
```

- Distribution of target variable

```{python}
#| label: fig-polar1
#| fig-cap: Distribution of Target Variable (Approved) 


# Plot the distribution of the target variable
sns.countplot(data=data_imputed, x="Approved",hue = "Approved", palette="viridis")
plt.xlabel("Approval Status")
plt.ylabel("Count")
plt.show()
```

## Bayesian Classifier Implementation 

- Define Priors: 

  → Calculate prior probabilities

```{python}
prior_approved = data["Approved"].value_counts(normalize=True)["+"]
prior_denied = data["Approved"].value_counts(normalize=True)["-"]

print(f"Prior P(Approved): {prior_approved}, P(Denied): {prior_denied}")
```
 
- Likelihood Estimation: 

  → Fit a Gaussian for 'Income' by class

```{python}
from scipy.stats import norm

approved_income = data[data["Approved"] == "+"]["Income"]
denied_income = data[data["Approved"] == "-"]["Income"]

likelihood_approved = norm(approved_income.mean(), approved_income.std())
likelihood_denied = norm(denied_income.mean(), denied_income.std())
```


- Posterior Calculation: 

  → Using Bayes' theorum to compute posterior porbabilities:

    $$P(\text{Approved}|\text{Income})=\frac{P(\text{Income}|\text{Approved})\cdot P(\text{Approved})}{P(\text{Income})}$$

```{python}
def posterior(income, prior, likelihood):
    return prior * likelihood.pdf(income)

# New applicant with income=5000
new_income = 5000
p_approved = posterior(new_income, prior_approved, likelihood_approved)
p_denied = posterior(new_income, prior_denied, likelihood_denied)

# Normalize posteriors
total_prob = p_approved + p_denied
p_approved /= total_prob
p_denied /= total_prob

print(f"P(Approved|Income): {p_approved}, P(Denied|Income): {p_denied}")
```

- Map Decision:

  → The class with highest posterior probability:
  
```{python}
decision = "Approved" if p_approved > p_denied else "Denied"
print(f"Decision: {decision}")
```


- Cost-Sensitive Decision:

  → Incoporated a cost matrix(eg - false negatives are more costly):
  
```{python}
# Cost matrix: [ [TN, FP], [FN, TP] ]
cost_matrix = [[0, 1], [5, 0]]  # High cost for FN

# expected cost
expected_cost_approved = cost_matrix[1][0] * p_denied  # FN cost
expected_cost_denied = cost_matrix[0][1] * p_approved  # FP cost

final_decision = "Approved" if expected_cost_approved < expected_cost_denied else "Denied"
print(f"Cost-sensitive Decision: {final_decision}")
```


## Model Evaulation 

- Evaulated the models performance with metrics like accuracy, precision, and recall. 

```{python}
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score, precision_score, recall_score
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

# Split the data into features and target
X = data_imputed.drop(columns=["Approved"])
y = data_imputed["Approved"]

# Identify categorical columns
categorical_columns = X.select_dtypes(include=["object"]).columns

# Apply one-hot encoding to categorical columns
X_encoded = pd.get_dummies(X, columns=categorical_columns, drop_first=True)



# Split the dataset into training and test sets (70% train, 30% test)
X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.3, random_state=42)

# Initialize the Naive Bayes classifier
model = GaussianNB()

# Train the model
model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = model.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, pos_label='+')
recall = recall_score(y_test, y_pred, pos_label='+')
```


## Results

```{python}
from sklearn.metrics import f1_score

f1 = f1_score(y_test, y_pred, pos_label='+')
print(f"F1 Score: {f1:.4f}")
print(f"Accuracy: {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
```

