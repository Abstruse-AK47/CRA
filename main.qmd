---
title: Credit Risk Assesment using bayesian Decision Thoery with noisy Financial Data 
format:
 html:
     code-fold: true
jupyter: python3
---

```{python}
import pandas as pd
import numpy as np
```

## Load UCI Credit Approval dataset

```{python}

url = "https://archive.ics.uci.edu/ml/machine-learning-databases/credit-screening/crx.data"
columns = ["Gender", "Age", "Debt", "Married", "BankCustomer", 
           "EducationLevel", "Ethnicity", "YearsEmployed", 
           "PriorDefault", "Employed", "CreditScore", 
           "DriversLicense", "Citizen", "ZipCode", "Income", "Approved"]

# Replace '?' with NaN
data = pd.read_csv(url, names=columns, na_values="?")

data.head()
```

## Add noise to 'Income' column

- Simulating Noisy Features:

  → Added Gaussian noise to numeric columns(eg.,income):

```{python}

noise_level = 0.1  # 10% noise
data["Income_noisy"] = data["Income"] + np.random.normal(0, noise_level * data["Income"].std(), len(data))

# Replace 'Income' with noisy version for simulation
data["Income"] = data["Income_noisy"]
data.drop(columns=["Income_noisy"], inplace=True)
```

## Handling Missing Data 

- Identify non-numeric columns

```{python}
non_numeric_columns = data.select_dtypes(include=["object"]).columns
non_numeric_columns
```

- Separate numeric and non-numeric columns and calculate missing data

```{python}
from sklearn.impute import SimpleImputer

numeric_data = data.select_dtypes(include=["number"])
categorical_data = data.select_dtypes(exclude=["number"])

# Impute numeric columns
imputer_numeric = SimpleImputer(strategy="mean")
numeric_data_imputed = pd.DataFrame(imputer_numeric.fit_transform(numeric_data), columns=numeric_data.columns)

# Impute categorical columns (e.g., with the most frequent value)
imputer_categorical = SimpleImputer(strategy="most_frequent")
categorical_data_imputed = pd.DataFrame(imputer_categorical.fit_transform(categorical_data), columns=categorical_data.columns)

# Combine numeric and categorical data
data_imputed = pd.concat([numeric_data_imputed, categorical_data_imputed], axis=1)

# Check the final imputed dataset
data_imputed.head()
```
## Dataset Visualization

- Distribution of target variable

```{python}
#| label: fig-polar
#| fig-cap: Distribution of Target Variable (Approved) 

import matplotlib.pyplot as plt
import seaborn as sns

# Plot the distribution of the target variable
sns.countplot(data=data_imputed, x="Approved",hue = "Approved", palette="viridis")
plt.xlabel("Approval Status")
plt.ylabel("Count")
plt.show()
```

- Pairplot of Feature Relationships

```{python}
#| label: fig-polar1
#| fig-cap: Pairplot of Features by Approval Status
data_without_zip = data_imputed.drop(columns=["ZipCode"])

# pairplot without the 'ZipCode' feature
sns.pairplot(data_without_zip, hue="Approved", diag_kind="kde", palette="coolwarm",height=1 ,aspect=1)
plt.show()
```
## Visualizing Missing Data

```{python}
#| label: fig-polar2
#| fig-cap: Missing Values Matrix
import missingno as msno

# Visualize missing data
msno.matrix(data)
plt.show()

```

## Bayesian Classifier Implementation 

- Define Priors: 

  → Calculate prior probabilities

```{python}
prior_approved = data["Approved"].value_counts(normalize=True)["+"]
prior_denied = data["Approved"].value_counts(normalize=True)["-"]

print(f"Prior P(Approved): {prior_approved}, P(Denied): {prior_denied}")
```
 
- Likelihood Estimation: 

  → Fit a Gaussian for 'Income' by class

```{python}
from scipy.stats import norm

approved_income = data[data["Approved"] == "+"]["Income"]
denied_income = data[data["Approved"] == "-"]["Income"]

likelihood_approved = norm(approved_income.mean(), approved_income.std())
likelihood_denied = norm(denied_income.mean(), denied_income.std())
```


- Posterior Calculation: 

  → Using Bayes' theorum to compute posterior porbabilities:

    $$P(\text{Approved}|\text{Income})=\frac{P(\text{Income}|\text{Approved})\cdot P(\text{Approved})}{P(\text{Income})}$$

```{python}
def posterior(income, prior, likelihood):
    return prior * likelihood.pdf(income)

# New applicant with income=5000
new_income = 5000
p_approved = posterior(new_income, prior_approved, likelihood_approved)
p_denied = posterior(new_income, prior_denied, likelihood_denied)

# Normalize posteriors
total_prob = p_approved + p_denied
p_approved /= total_prob
p_denied /= total_prob

print(f"P(Approved|Income): {p_approved}, P(Denied|Income): {p_denied}")
```

## Decision Rule

- Map Decision:

  → The class with highest posterior probability:

```{python}
decision = "Approved" if p_approved > p_denied else "Denied"
print(f"Decision: {decision}")
```

- Cost-Sensitive Decision:

  → Incoporated a cost matrix(eg - false negatives are more costly):
  
```{python}
# Cost matrix: [ [TN, FP], [FN, TP] ]
cost_matrix = [[0, 1], [5, 0]]  # High cost for FN

# expected cost
expected_cost_approved = cost_matrix[1][0] * p_denied  # FN cost
expected_cost_denied = cost_matrix[0][1] * p_approved  # FP cost

final_decision = "Approved" if expected_cost_approved < expected_cost_denied else "Denied"
print(f"Cost-sensitive Decision: {final_decision}")
```


```{python}
#| label: fig-polar3
#| fig-cap: Distribution of Features 
import math

# List of columns to plot
columns_to_plot = ["CreditScore", "Age", "Debt", "Income"]

# Calculate rows and columns for a grid
n_features = len(columns_to_plot)
n_cols = 2  # Number of columns in the grid
n_rows = math.ceil(n_features / n_cols)  # Calculate required rows (3 in this case)

# Create subplots
fig, axes = plt.subplots(n_rows, n_cols, figsize=(6, 5))  # Adjust size as needed
axes = axes.flatten()  # Flatten to easily index subplots

# Plot each feature
for i, col in enumerate(columns_to_plot):
    sns.histplot(data_imputed[col], kde=True, bins=30, color="blue", ax=axes[i])
    axes[i].set_xlabel(col, fontsize=8)
    axes[i].set_ylabel("Frequency", fontsize=8)
    axes[i].tick_params(axis="both", labelsize=7)

# Remove any unused axes
for j in range(i + 1, len(axes)):
    fig.delaxes(axes[j])

# Adjust layout
plt.tight_layout()
plt.show()

```

```{python}
#| label: fig-polar4
#| fig-cap: Correlation Heatmap 

# Correlation heatmap
numeric_data_usefull = numeric_data.drop(columns= ["ZipCode","YearsEmployed"])
plt.figure(figsize=(10, 8))
sns.heatmap(numeric_data_usefull.corr(), annot=True, cmap="coolwarm", fmt=".2f")
plt.show()

```
## Model Evaulation 

- Evaulated the models performance with metrics like accuracy, precision, and recall. 

```{python}
#| label: fig-polar5
#| fig-cap: Confusion Matrix 

from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score, precision_score, recall_score
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

# Split the data into features and target
X = data_imputed.drop(columns=["Approved"])
y = data_imputed["Approved"]

# Identify categorical columns
categorical_columns = X.select_dtypes(include=["object"]).columns

# Apply one-hot encoding to categorical columns
X_encoded = pd.get_dummies(X, columns=categorical_columns, drop_first=True)



# Split the dataset into training and test sets (70% train, 30% test)
X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.3, random_state=42)

# Initialize the Naive Bayes classifier
model = GaussianNB()

# Train the model
model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = model.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, pos_label='+')
recall = recall_score(y_test, y_pred, pos_label='+')

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred, labels=model.classes_)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)
disp.plot(cmap="Blues")
plt.show()
```


## Results

```{python}
from sklearn.metrics import f1_score

f1 = f1_score(y_test, y_pred, pos_label='+')
print(f"F1 Score: {f1:.4f}")
print(f"Accuracy: {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
```

```{python}
#| label: fig-polar6
#| fig-cap: Model Performance Metrics

# Bapr Plot of Model Metrics
metrics = ["Accuracy", "Precision", "Recall", "F1 Score"]
scores = [accuracy, precision, recall,f1]

plt.figure(figsize=(8, 5))
sns.barplot(x=metrics, y=scores, hue = metrics, palette="viridis")
plt.ylim(0, 1)
plt.ylabel("Score")
plt.savefig('output.jpg')
plt.show()
```

```{python}
#| label: fig-polar7
#| fig-cap: Precision-Recall Curve 

# Precision-Recall Curve
from sklearn.metrics import precision_recall_curve
precision, recall, thresholds = precision_recall_curve(y_test, model.predict_proba(X_test)[:, 1], pos_label='+')
plt.figure(figsize=(8, 6))
plt.plot(recall, precision, marker=".", label="Naive Bayes")
plt.xlabel("Recall")
plt.ylabel("Precision")
plt.grid()
plt.legend()
plt.show()
```
